{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ffab67df-ef61-4311-9831-acd0e78a6e9a",
   "metadata": {},
   "source": [
    "# Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31c5d776-eee9-4b87-923f-74dfa44785fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import igraph as ig\n",
    "ig.config[\"plotting.backend\"] = \"matplotlib\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "111e125c-00a6-4f69-ad64-a29a05028ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_graph_from_gml_file(graph_file: str, weight_attribute_name: str = \"weight\"):\n",
    "    import os\n",
    "    # Check if the graph file exists\n",
    "    if not os.path.exists(graph_file):\n",
    "        print(f\"Error: Graph file '{graph_file}' not found.\")\n",
    "        print(f\"Please ensure '{graph_file}' is a valid path to your 'lesmis.gml' file.\")\n",
    "        print(\"You can typically find this file by searching for 'lesmis.gml network dataset'.\")\n",
    "        return # Exit the function if file is not found\n",
    "\n",
    "    try:\n",
    "        # Load network from GML file\n",
    "        # igraph.Graph.Read_GML will automatically load edge attributes like 'value'\n",
    "        # if they are present in the GML file.\n",
    "        graph = ig.Graph.Read_GML(graph_file)\n",
    "        \n",
    "        # Check if the graph has the correct weight attribute name\n",
    "        if weight_attribute_name not in graph.edge_attributes():\n",
    "            print(f\"Warning: Graph '{graph_file}' does not have a '{weight_attribute_name}' attribute. \"\n",
    "                  \"Community detection will proceed without explicit weights, or if the algorithm \"\n",
    "                  \"expects them, it might use default uniform weights.\")\n",
    "            # If no 'value' attribute, assign a default uniform weight for visualization purposes\n",
    "            graph.es[weight_attribute_name] = 1 \n",
    "\n",
    "        return graph\n",
    "\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while loading or processing the graph: {e}\")\n",
    "        return\n",
    "\n",
    "def community_detection(graph: ig.Graph, community_detection_method: str = \"multilevel\", weight_attribute_name: str = \"weight\", \n",
    "                        params: dict = None):\n",
    "    if community_detection_method == \"multilevel\":\n",
    "        return graph.community_multilevel(weights=weight_attribute_name if weight_attribute_name in graph.edge_attributes() else None)\n",
    "    elif community_detection_method == \"leiden\":\n",
    "        if params is None:\n",
    "            return graph.community_leiden(weights=weight_attribute_name if weight_attribute_name in graph.edge_attributes() else None)\n",
    "        else:\n",
    "            params[\"weights\"] = weight_attribute_name if weight_attribute_name in graph.edge_attributes() else None\n",
    "            return graph.community_leiden(**params)\n",
    "    elif community_detection_method == \"fastgreedy\":\n",
    "        return graph.community_fastgreedy(weights=weight_attribute_name if weight_attribute_name in graph.edge_attributes() else None).as_clustering()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e15bf0ab-7b54-4f89-b6f6-e49ae9de6c54",
   "metadata": {},
   "source": [
    "## Functions useful to test community structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ab35a72-4bcd-4391-8f28-85b39c6a29ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_modularity_on_clustering(graph: ig.Graph, community_detection_method: str = \"multilevel\", params: dict = None):\n",
    "    partition = community_detection(graph, community_detection_method, weight_attribute_name=None, params=params)\n",
    "    return partition.modularity\n",
    "\n",
    "def rewire(graph: ig.Graph, community_detection_method: str = \"multilevel\", params: dict = None):\n",
    "    num_randomizations = 500  # Number of randomized networks to generate\n",
    "    modularity_random_networks = []\n",
    "    \n",
    "    num_swaps_for_randomization = graph.ecount() * 10\n",
    "    \n",
    "    for i in range(num_randomizations):\n",
    "        # G.rewire() modifies the graph in-place, so we must work on a copy.\n",
    "        graph_random = graph.copy()\n",
    "    \n",
    "        graph_random.rewire(n=num_swaps_for_randomization)\n",
    "    \n",
    "        modularity_random_networks.append(get_modularity_on_clustering(graph_random))\n",
    "\n",
    "    return modularity_random_networks\n",
    "\n",
    "def plot_histogram(modularity_original: float, modularity_random_networks: list[float], graph_name: str=\"Karate Club Network\"):\n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.hist(modularity_random_networks, bins=30, alpha=0.7, color='lightgreen',\n",
    "             edgecolor='black', label='Modularity of Randomized Networks')\n",
    "    \n",
    "    # Set x-axis limits from 0 to 1\n",
    "    plt.xlim(0, 1)\n",
    "    \n",
    "    # Plot a vertical line for the original network's modularity\n",
    "    plt.axvline(modularity_original, color='red', linestyle='dashed', linewidth=2,\n",
    "                label=f'Original Network Modularity ({modularity_original:.4f})')\n",
    "    \n",
    "    plt.title(f'Modularity of Original vs. Randomized {graph_name} (igraph)')\n",
    "    plt.xlabel('Modularity Score')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.legend()\n",
    "    plt.grid(axis='y', alpha=0.75)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def test_community_structure(graph: ig.Graph, graph_name: str = \"Karate Club Network\", community_detection_method: str = \"multilevel\", \n",
    "                             params: dict = None):\n",
    "    modularity_orig = get_modularity_on_clustering(graph, community_detection_method, params)\n",
    "    modularity_random_networks = rewire(graph, community_detection_method, params)\n",
    "    plot_histogram(modularity_orig, modularity_random_networks, graph_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32c6168e-c9d8-4200-a7ef-fac6927408d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_key_existence(keys, params):\n",
    "    return all(key in params for key in keys)\n",
    "    \n",
    "\n",
    "def build_community_detection_method(graph, community_detection_method, params):\n",
    "    community_detection = None\n",
    "    if community_detection_method == \"leiden\":\n",
    "        if params is None:\n",
    "            raise ValueError(\"params must not be None\")\n",
    "        if not check_key_existence([\"resolution\"], params):\n",
    "            raise KeyError(\"Key not found in params\")\n",
    "        resolution_list = params[\"resolution\"]\n",
    "        leiden_other_params = {k: v for k, v in params.items() if k != \"resolution\"}\n",
    "        community_detection = lambda seed_idx: graph.community_leiden(resolution=resolution_list[seed_idx], **leiden_other_params)\n",
    "    elif community_detection_method == \"multilevel\":\n",
    "        community_detection = lambda _: graph.community_multilevel(**(params if params else {})) # Pass original params if any, or empty dict\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown community detection method: {community_detection_method}\")\n",
    "\n",
    "    if community_detection is None:\n",
    "        raise RuntimeError(\"Failed to set up community_detector_executor.\")\n",
    "\n",
    "    return community_detection\n",
    "\n",
    "\n",
    "# A helper function to run a target function with a timeout using multiprocessing\n",
    "def _run_with_timeout(func, args=(), kwargs={}, timeout_seconds=60):\n",
    "    \"\"\"\n",
    "    Runs a function in a separate process with a timeout.\n",
    "    Returns (result, True) if successful, (None, False) if timeout occurs.\n",
    "    \"\"\"\n",
    "    import multiprocessing\n",
    "    \n",
    "    # Use a multiprocessing.Queue to get the result from the child process\n",
    "    q = multiprocessing.Queue()\n",
    "    \n",
    "    def target():\n",
    "        try:\n",
    "            res = func(*args, **kwargs)\n",
    "            q.put((res, None)) # Put result and no exception\n",
    "        except Exception as e:\n",
    "            q.put((None, e)) # Put no result and the exception\n",
    "\n",
    "    process = multiprocessing.Process(target=target)\n",
    "    process.start()\n",
    "    process.join(timeout=timeout_seconds)\n",
    "\n",
    "    if process.is_alive():\n",
    "        # If the process is still alive, it means it timed out\n",
    "        print(f\"Warning: Function '{func.__name__}' timed out after {timeout_seconds} seconds. Terminating process.\")\n",
    "        process.terminate() # Forcefully terminate the process\n",
    "        process.join() # Wait for termination\n",
    "        time.sleep(0.01) # Small delay to allow OS cleanup after termination attempt\n",
    "        return None, False, None # Return None result, False for success, None for exception\n",
    "    else:\n",
    "        # Process finished, check for result or exception\n",
    "        if not q.empty():\n",
    "            res, exception = q.get()\n",
    "            if exception:\n",
    "                raise exception # Re-raise any exception caught in the process\n",
    "            return res, True, None # Return result, True for success\n",
    "        else:\n",
    "            # This case might happen if process terminates unexpectedly without putting anything\n",
    "            print(f\"Warning: Process for '{func.__name__}' finished but no result was put in queue.\")\n",
    "            return None, False, None\n",
    "\n",
    "\n",
    "def generate_reference_partition(graph: ig.Graph, optimal_timeout_seconds: int, use_optimal_as_reference: bool = True):\n",
    "    import random\n",
    "    \n",
    "    reference_partition = None\n",
    "    if use_optimal_as_reference:\n",
    "        ref_partition_result, success, exception = _run_with_timeout(\n",
    "            graph.community_optimal_modularity,\n",
    "            timeout_seconds=optimal_timeout_seconds\n",
    "        )\n",
    "        if success and ref_partition_result is not None:\n",
    "            reference_partition = ref_partition_result\n",
    "            print(f\"Optimal partition found with modularity: {reference_partition.modularity:.4f}\")\n",
    "        else:\n",
    "            if exception:\n",
    "                print(f\"Optimal partition calculation failed with error: {exception}\")\n",
    "            print(\"Falling back to a fixed-seed Louvain partition as reference.\")\n",
    "            # Fallback for larger graphs or if optimal fails/times out\n",
    "            random.seed(42) # Fix seed for a reproducible reference\n",
    "            reference_partition = graph.community_multilevel()\n",
    "            random.seed(None) # Unset seed for subsequent stochastic runs\n",
    "            print(f\"Reference Louvain partition (fixed seed) found with modularity: {reference_partition.modularity:.4f}\")\n",
    "    else:\n",
    "        # Option B: Louvain with fixed seed as reference (for larger graphs)\n",
    "        print(\"\\nUsing a fixed-seed Louvain partition as reference.\")\n",
    "        random.seed(42) # Fix seed for a reproducible reference\n",
    "        reference_partition = graph.community_multilevel()\n",
    "        random.seed(None) # Unset seed for subsequent stochastic runs\n",
    "        print(f\"Reference Louvain partition (fixed seed) found with modularity: {reference_partition.modularity:.4f}\")\n",
    "\n",
    "    \n",
    "    if reference_partition is None:\n",
    "        raise(\"Could not establish a reference partition\")\n",
    "\n",
    "    return reference_partition\n",
    "\n",
    "def run_stochastic_community_detection(graph, reference_partition: ig.clustering.VertexClustering, num_runs: int, \n",
    "                                       community_detection_method: str = \"multilevel\", return_partitions: bool = False,\n",
    "                                      params: dict = None):\n",
    "    import random\n",
    "    \n",
    "    nmi_values = []\n",
    "    all_partitions = []\n",
    "    print(f\"\\nRunning Louvain community detection {num_runs} times and calculating NMI...\")\n",
    "\n",
    "    community_detection = build_community_detection_method(graph, community_detection_method, params)\n",
    "\n",
    "    for i in range(num_runs):\n",
    "        random.seed()\n",
    "        current_partition = community_detection(i)\n",
    "        all_partitions.append(current_partition)\n",
    "\n",
    "        if not return_partitions:\n",
    "            # Calculate NMI between the current partition and the reference partition\n",
    "            # 'method='nmi'' specifies Normalized Mutual Information\n",
    "            nmi = ig.compare_communities(reference_partition, current_partition, method='nmi')\n",
    "            nmi_values.append(nmi)\n",
    "\n",
    "        if (i + 1) % (num_runs // 10 if num_runs >= 10 else 1) == 0:\n",
    "            print(f\"  Processed {i + 1}/{num_runs} runs.\")\n",
    "\n",
    "    if return_partitions:\n",
    "        return all_partitions\n",
    "        \n",
    "    return nmi_values\n",
    "\n",
    "def plot_nmi_histogram(graph: ig.Graph, nmi_values: list[float], title: str):\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.hist(nmi_values, bins=20, edgecolor='black', alpha=0.7, color='lightcoral')\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Normalized Mutual Information (NMI) Score')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.grid(axis='y', alpha=0.75)\n",
    "    \n",
    "    # Set x-axis limits from 0 to 1\n",
    "    plt.xlim(0, 1)\n",
    "\n",
    "    # Add a line for the mean NMI\n",
    "    mean_nmi = np.mean(nmi_values)\n",
    "    plt.axvline(mean_nmi, color='blue', linestyle='dashed', linewidth=2,\n",
    "                label=f'Mean NMI: {mean_nmi:.4f}')\n",
    "\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def calculate_pairwise_nmi(partitions: list[ig.clustering.VertexClustering]):\n",
    "    \"\"\"\n",
    "    Calculates Normalized Mutual Information (NMI) for all unique pairs of partitions.\n",
    "    \"\"\"\n",
    "    import itertools\n",
    "    \n",
    "    pairwise_nmi_values = []\n",
    "    for p1, p2 in itertools.combinations(partitions, 2):\n",
    "        nmi = ig.compare_communities(p1, p2, method='nmi')\n",
    "        pairwise_nmi_values.append(nmi)\n",
    "    return pairwise_nmi_values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e018281-2fe7-4c7c-b608-c2e97e315e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_grid_graph(rows, cols, circular=False):\n",
    "    \"\"\"\n",
    "    Generates a 2D grid graph (lattice) without plotting.\n",
    "    Returns the graph and its column count for later layout.\n",
    "    \"\"\"\n",
    "    G = ig.Graph.Lattice(dim=[rows, cols], nei=1, circular=circular)\n",
    "    return G\n",
    "\n",
    "# --- Final version of cluster_and_plot_leiden with grid_cols ---\n",
    "def cluster_and_plot_leiden_on_grid(graph, grid_cols, title=\"Graph with Leiden Communities\", plot_size=(8, 8)):\n",
    "    \"\"\"\n",
    "    Clusters a graph using the Leiden algorithm and plots the result\n",
    "    with vertices colored by their community, specifically for grid layouts.\n",
    "\n",
    "    Args:\n",
    "        graph (igraph.Graph): The graph to cluster.\n",
    "        grid_cols (int): The number of columns the grid graph has. Crucial for layout.\n",
    "        title (str): Title for the plot.\n",
    "        plot_size (tuple): Size of the matplotlib figure (width, height).\n",
    "\n",
    "    Returns:\n",
    "        igraph.clustering.VertexClustering: The community detection result.\n",
    "    \"\"\"\n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    print(f\"Clustering graph with {graph.vcount()} vertices and {graph.ecount()} edges using Leiden algorithm...\")\n",
    "\n",
    "    resolution = 0.15\n",
    "    communities = graph.community_leiden(objective_function=\"modularity\", resolution=resolution)\n",
    "\n",
    "    # Assign colors based on community membership\n",
    "    palette = ig.GradientPalette(\"red\", \"blue\", n=len(communities)) \n",
    "    if len(communities) > 1:\n",
    "        vertex_colors = [palette.get(membership_id) for membership_id in communities.membership]\n",
    "    else:\n",
    "        vertex_colors = [\"red\"]\n",
    "    \n",
    "    # Generate the grid layout using the provided grid_cols\n",
    "    layout = graph.layout_grid(width=grid_cols)\n",
    "            \n",
    "    fig, ax = plt.subplots(figsize=plot_size)\n",
    "\n",
    "    ig.plot(\n",
    "        graph,\n",
    "        target=ax,\n",
    "        layout=layout,\n",
    "        vertex_size=10,\n",
    "        vertex_color=vertex_colors, # Use community colors\n",
    "        vertex_label=None,\n",
    "        edge_width=0.8,\n",
    "        edge_color=\"gray\",\n",
    "        bbox=(0, 0, 600, 600),\n",
    "        margin=20\n",
    "    )\n",
    "    ax.set_title(title)\n",
    "    ax.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "    return communities, resolution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9125e0e-d55d-473a-8522-9d4ef36e1309",
   "metadata": {},
   "source": [
    "## Game of Thrones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "19c48c09-5220-446f-873d-1cbdc44174cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_got_network(url: str = None):\n",
    "    import pandas as pd\n",
    "    import requests\n",
    "    import io\n",
    "    \n",
    "    if url is None:\n",
    "        # URL of the raw CSV data for Season 1 edges\n",
    "        url = \"https://raw.githubusercontent.com/mathbeveridge/gameofthrones/master/data/got-s1-edges.csv\"\n",
    "    \n",
    "    # Fetch the data from the URL\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status() # Raise an HTTPError for bad responses (4xx or 5xx)\n",
    "        season1_edges_data = io.StringIO(response.text)\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error fetching data from {url}: {e}\")\n",
    "        print(\"Please ensure you have an active internet connection or download the file manually.\")\n",
    "        exit()\n",
    "        \n",
    "    # Load the data into a pandas DataFrame\n",
    "    df_s1_edges = pd.read_csv(season1_edges_data)\n",
    "    \n",
    "    # Create an igraph graph\n",
    "    # Assuming 'Source' and 'Target' are the columns for the edges\n",
    "    # And 'Weight' is the column for edge weights (if present)\n",
    "    \n",
    "    # Check if 'Weight' column exists\n",
    "    if 'Weight' in df_s1_edges.columns:\n",
    "        # Prepare data as list of (source, target, weight) tuples\n",
    "        edges_for_tuplelist = df_s1_edges[['Source', 'Target', 'Weight']].values.tolist()\n",
    "    \n",
    "        g_s1 = ig.Graph.TupleList(edges_for_tuplelist,\n",
    "                                 directed=False,\n",
    "                                 weights=True) # This tells igraph the 3rd element in the tuple is the weight\n",
    "        print(\"Graph created with edge weights using weights=True.\")\n",
    "    else:\n",
    "        g_s1 = ig.Graph.TupleList(df_s1_edges[['Source', 'Target']].itertuples(index=False),\n",
    "                                  directed=False) # Assuming interactions are undirected\n",
    "        print(\"\\nGraph created without edge weights.\")\n",
    "\n",
    "    return g_s1\n",
    "\n",
    "    \n",
    "def graph_summary(g: ig.Graph):\n",
    "    print(f\"\\n--- Graph Summary for Season 1 ---\")\n",
    "    print(f\"Number of vertices (characters): {g.vcount()}\")\n",
    "    print(f\"Number of edges (interactions): {g.ecount()}\")\n",
    "    print(f\"Is graph directed? {g.is_directed()}\")\n",
    "    print(f\"Graph attributes: {g.attributes()}\")\n",
    "    print(f\"Vertex attributes: {g.vs.attributes()}\")\n",
    "    print(f\"Edge attributes: {g.es.attributes()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fbd148a-f723-4f80-acad-1d656d693b5f",
   "metadata": {},
   "source": [
    "## Community detection table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fe07e5ab-d0f3-4236-b41a-ac888b1eaeb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_table():\n",
    "    import pandas as pd\n",
    "    from itables import init_notebook_mode, show\n",
    "    \n",
    "    # This line enables itables to make all DataFrames interactive by default\n",
    "    # If you only want specific tables to be interactive, remove this line and use show(df) explicitly\n",
    "    init_notebook_mode(all_interactive=True)\n",
    "    \n",
    "    # Your DataFrame creation code (as before)\n",
    "    data = {\n",
    "        'Method': ['Edge Betweenness', 'Fast-Greedy', 'Fluid Communities', 'Infomap', 'Label Propagation', 'Leading Eigenvector', 'Leiden', 'Louvain (Multilevel)', 'Spinglass', 'Walktrap', 'Optimal Modularity', 'Voronoi'],\n",
    "        'Function in igraph (Python)': ['`Graph.community_edge_betweenness()`', '`Graph.community_fastgreedy()`', '`Graph.community_fluid_communities()`', '`Graph.community_infomap()`', '`Graph.community_label_propagation()`', '`Graph.community_leading_eigenvector()`', '`Graph.community_leiden()`', '`Graph.community_multilevel()`', '`Graph.community_spinglass()`', '`Graph.community_walktrap()`', '`Graph.community_optimal_modularity()`', '`Graph.community_voronoi()`'],\n",
    "        'Directed Graph Support': ['✅', '❌', '❌', '✅', '❌', '❌', '❌', '✅', '❌', '❌', '❌', '✅'],\n",
    "        'Weighted Graph Support': ['✅', '✅', '❌ (weights ignored)', '✅', '✅', '✅', '✅', '✅', '✅', '✅', '✅', '✅'],\n",
    "        'Signed Graph Support': ['❌', '❌', '❌', '❌', '❌', '❌', '❌', '❌', '✅', '❌', '❌', '❌'],\n",
    "        'Sparse Graph Performance': ['✅', '✅ (Very efficient)', '✅', '✅', '✅', '✅', '✅', '✅', '✅', '✅', '❌ (Small graphs only)', '✅'],\n",
    "        'Dense Graph Performance': ['❌ (Slow for large)', '✅ (Can handle)', '✅', '✅', '✅', '✅', '✅', '✅', '❌ (Slower)', '✅', '❌ (Small graphs only)', '✅'],\n",
    "        'Deterministic': ['✅', '❌', '❌', '❌', '❌', '✅', '❌', '❌', '❌', '✅', '✅', '✅'],\n",
    "        'Notes': [\n",
    "            'Divisive hierarchical method. Good for small to medium graphs. Returns a dendrogram. Modularity-based partition can be extracted. The underlying modularity is typically for undirected graphs.',\n",
    "            'Agglomerative, modularity-maximization method. Returns a dendrogram. Efficient for large sparse graphs. Suffers from resolution limit. (Non-deterministic due to greedy choices / tie-breaking)',\n",
    "            'Propagation-based. Requires `k` (number of communities) as input. Stochastic. Very fast and scalable. Primarily for unweighted, undirected graphs. (Non-deterministic due to random seeds/updates)',\n",
    "            'Based on information theory (minimizing description length of random walks). Can handle directed and weighted graphs. (Non-deterministic due to random walks)',\n",
    "            'Fast, propagation-based. (Non-deterministic due to random initialization/tie-breaking). Uses `directed` parameter to respect edge direction.',\n",
    "            'Modularity-maximization (spectral method). Finds highest modularity partition. Can be slow for very large graphs. For undirected, weighted graphs.',\n",
    "            'Improvement over Louvain. Guarantees well-connected communities. Usually higher modularity and more stable than Louvain. Can use resolution parameter. Highly recommended for general use. (Non-deterministic due to local moves/tie-breaking)',\n",
    "            'Greedy, iterative modularity optimization. Fast and scalable. Returns hierarchical partition. Can suffer from resolution limit and potentially disconnected communities. (Non-deterministic due to local moves/tie-breaking)',\n",
    "            'Based on statistical mechanics (Ising model and simulated annealing). Can handle negative weights (as \"frustration\"). Can be computationally intensive, especially for dense or large graphs. Allows for fixed number of spins (`k`). (Stochastic by design)',\n",
    "            'Based on random walks. Merges communities that random walks tend to stay within. Hierarchical output (dendrogram). Efficient for sparse graphs.',\n",
    "            'Finds the **exact** highest modularity partition. Computationally very expensive. Only practical for very small graphs (dozens to ~100 nodes).',\n",
    "            'Partitions nodes into \"cells\" based on proximity (e.g., shortest path distance) to pre-defined \"seed\" nodes. Not a direct community *discovery* algorithm; it *assigns* based on input seeds. Used when node coordinates or influence regions are relevant.'\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    # To display the DataFrame with interactive features, including sticky headers AND frozen first column\n",
    "    show(df, scrollY=\"300px\", scrollCollapse=True, fixedColumns=True, pageLength=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8575f2b2-a73e-400f-af14-f6c833657a43",
   "metadata": {},
   "source": [
    "## Resolution parameter on Sierpinski"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9181bf9-eaf5-488b-a600-c5e3db066240",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sierpinski_graph_and_layout(depth):\n",
    "    \"\"\"\n",
    "    Generates a Sierpiński triangle graph with unique vertices and its coordinate layout.\n",
    "    \"\"\"\n",
    "    import igraph as ig\n",
    "    import numpy as np\n",
    "    \n",
    "    G = ig.Graph()\n",
    "    if depth < 0:\n",
    "        return G, []\n",
    "    \n",
    "    # Use a dictionary to map coordinates to a single vertex ID\n",
    "    coord_to_id = {}\n",
    "    next_id = 0\n",
    "    \n",
    "    def get_or_create_vertex(coord):\n",
    "        nonlocal next_id\n",
    "        coord_tuple = tuple(coord)\n",
    "        if coord_tuple not in coord_to_id:\n",
    "            coord_to_id[coord_tuple] = next_id\n",
    "            G.add_vertex(coords=coord_tuple)\n",
    "            next_id += 1\n",
    "        return coord_to_id[coord_tuple]\n",
    "    \n",
    "    def add_triangle(g, p1, p2, p3, d):\n",
    "        if d == 0:\n",
    "            v_p1 = get_or_create_vertex(p1)\n",
    "            v_p2 = get_or_create_vertex(p2)\n",
    "            v_p3 = get_or_create_vertex(p3)\n",
    "            \n",
    "            if not g.are_adjacent(v_p1, v_p2): g.add_edge(v_p1, v_p2)\n",
    "            if not g.are_adjacent(v_p2, v_p3): g.add_edge(v_p2, v_p3)\n",
    "            if not g.are_adjacent(v_p3, v_p1): g.add_edge(v_p3, v_p1)\n",
    "        else:\n",
    "            a = ((p1[0] + p2[0]) / 2, (p1[1] + p2[1]) / 2)\n",
    "            b = ((p2[0] + p3[0]) / 2, (p2[1] + p3[1]) / 2)\n",
    "            c = ((p3[0] + p1[0]) / 2, (p3[1] + p1[1]) / 2)\n",
    "            \n",
    "            add_triangle(g, p1, a, c, d - 1)\n",
    "            add_triangle(g, a, p2, b, d - 1)\n",
    "            add_triangle(g, c, b, p3, d - 1)\n",
    "\n",
    "    p1, p2, p3 = (0, 0), (1, 0), (0.5, np.sqrt(3)/2)\n",
    "    add_triangle(G, p1, p2, p3, depth)\n",
    "\n",
    "    layout = [v['coords'] for v in G.vs]\n",
    "    return G, layout\n",
    "\n",
    "def draw_sierpinski_igraph_on_axes(depth, ax):\n",
    "    \"\"\"\n",
    "    Generates and draws a Sierpiński triangle using igraph onto a given Matplotlib Axes.\n",
    "    \"\"\"\n",
    "    G, layout = get_sierpinski_graph_and_layout(depth)\n",
    "    ax.clear()\n",
    "    \n",
    "    if not G.vcount():\n",
    "        ax.set_title(f\"Sierpiński Triangle - Depth {depth} (No vertices)\")\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        ax.axis('off')\n",
    "        return\n",
    "\n",
    "    ig.plot(G, target=ax, layout=layout, vertex_size=5, vertex_color=\"black\", \n",
    "            vertex_label=None, edge_color=\"blue\", edge_width=1,\n",
    "            bbox=(0, 0, 600, 600), margin=20)\n",
    "    \n",
    "    ax.set_title(f\"Sierpiński Triangle - Depth {depth}\")\n",
    "    ax.set_aspect('equal', adjustable='box')\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    ax.axis('off')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
